<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Junsu Lee | Portfolio</title>

    <!-- favicons -->
    <link rel="apple-touch-icon" sizes="180x180" href="res/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="res/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="res/favicon-16x16.png">
    <link rel="manifest" href="res/site.webmanifest">

    <!-- fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,100..900;1,100..900&display=swap"
        rel="stylesheet">

    <!-- css -->
    <link rel="stylesheet" href="style.css">
    <!-- js -->
    <script src="script.js"></script>
</head>

<body>
    <nav id="topnav">
        <a href="index.html">Home</a>
        <a href="blog.html">Blog</a>
        <a href="projects.html">Projects</a>
        <a href="contact.html">Contact</a>
        <a href="resume.pdf">Résumé</a>
        <a href="https://github.com/junsoup">Github</a>
        <a href="javascript:void(0);" class="icon" onclick="toggleMenu()">&#9776;</a>
    </nav>
    <div class="banner-short"></div>
    <div class="content primary">
        <div class="container">
            <h2>Projects</h2>
            <hr>
        </div>
    </div>
    <div class="content primary">
        <div class="container">
            <h3>Biologically-inspired Neural Network</h3>
            <p>For a long-time now, I have been deeply unsatisfied with the current state of neural networks and specifically LLMs. The thing that bothers me the most are people saying things like, "OMG these chatbots like ChatGPT are so good at thinking!!!", stating how human-like they are. They do not think like humans do.</p>
            <p>Here is the clear issue with neural networks:</p>
            <ul>
                <li>They are first trained, then used in inference. Their neural weights do not change during runtime.</li>
                <li>They need a lot of data since they cannot "learn" in the traditional sense of learning through experiences.</li>
                <li>They are not time-dependent. Humans never stop thinking, unlike LLMs.</li>
            </ul>
            <p>Recently, I came across a paper released by Sakana AI called <a href="https://sakana.ai/ctm/">the Continuous Thought Machine</a>. It's an incredible paper and rethinks the traditional methods of neural networks. In short, they have a MLP that loops over ticks, instead of being feed-forward one time like most neural networks. In the output layer, they have per-neuron models that hold a history of information from previous ticks. These outputs are also fed into a history, a sync matrix is calculated, then finally the latent representation is computed. The model is trained like a traditional network, but only pull the output from the latent representation if the confidence is high enough. The outputs from the per-neuron models are fed back into the input, additionally, the environment input is modulated with a multi-attention head, which acts to preserve the current tick's thoughts onto the next tick. This makes the runtime indeterminant, but their paper shows incredible results.</p>
            <p>I think this is half the key to having true artificial intelligence. The other key is to learn dynamically instead of using backpropagation.</p>
            <p>With this, I came up with my own model that is Biologically-inspired:</p>
            <p>Here is the architecture:</p>
            <ul>
                <li>Looping MLP with sensory input (audio and vision)</li>
                <li>Biological neuron simulation instead of linear function with activation. Specifically the FitzHugh-Nagumo Model, which is a simplified version of the Hodgkin-Huxley model.</li>
                <li>Dynamically sized vision input.</li>
                <li>Sync matrix + latent representation</li>
                <li>Dynamic neuron weight updates via systems to act as forms of neuroplasticity.</li>
            </ul>
            <p>There's a lot here and honestly it seems pretty unlikely to be fruitful but I'll keep trying. I've implemented all parts except the last bullet point. Here is a teaser image</p>
            <img src="./res/CTM.png" alt="current state of brain model." style="width: 800px; max-width: 100%;">
        </div>
    </div>
    <div class="content secondary">
        <div class="container">
            <h3>Optimal Team Composition Finder</h3>
            <img src="./res/picker_tool.png" alt="Team picker webapp." style="width: 800px; max-width: 100%;">
            <p>This a project I have been working on for many years. I went into the details of this project on my blogs page. In summary, I developed a neural network to identify optimal characters to play in a competitive game by identifying key combinations of champions that synergize well while being good against the enemy champions.</p>
            <p>Things I used and learned:</p>
            <ul>
                <li>Data Augmentation</li>
                <li>One-hot encodings</li>
                <li>Embedding layers</li>
                <li>Cross-validation</li>
            </ul>
            <p>The problem itself is very difficult. Even if one team has a perfect team composition, those players can still be worse, or not be in the best condition, not focused, etc. With my best efforts, I was able to achieve an accuracy of 55% which seems to be the limit for this problem. I found commercial tools online that had basically the same accuracy with 10x the data I had.</p>
            <p>The largest boost to my accuracy was switching to embedding layers. Eliminates specific champion trends and treats champions more like specific types of gameplay. This solved the overfitting issue.</p>
            <p>You can read more on this on my blog page!</p>
        </div>
    </div>
    <div class="content primary">
        <div class="container">
            <h3>Koi Fish</h3>
            <img src="./res/fish.png" alt="Image of fish project" style="width: 800px; max-width: 100%;">
            <p>This is the project displayed on the home page. This was a larger endeavor than I thought initally.
                Some of the core things I learned/used in this project were:</p>
            <ul>
                <li>Mesh Instancing</li>
                <li>GTLF 2.0</li>
                <li>Blender (yes I learned 3D modeling for this)</li>
                <li>Vertex and Fragment shaders (offloading onto the GPU)</li>
                <li>Boids algorithm for flocking(?) fish</li>
            </ul>
            <p>Boids by itself fairly trivial, but an additional requirement I made was for the fish to A) have boundary logic, and B) also swim for food when the user feeds them. This made the project a bit more challenging. Also, you might have noticed if you refreshed the page a couple times, is that the koi fish color patterns are random. I did this by applying a 3d Simplex noise function to the fish with per instance random offsets in the vertex shader. Colorful (and unique) fish!</p>
            <p>I also learned how to 3D model, and to create materials. I happily embraced the low-poly style since anything more would be way too difficult.</p>
            <p>In '_banner_pixelated.js', I attempted to make a pixel-art styled renderer for this, but it didn't feel quite right so I scrapped it.</p>
        </div>
    </div>
    <div class="content secondary">
        <div class="container">
            <h3>Apple Destroyer</h3>
            <img src="./res/apple.jpg" alt="Image of apple project" style="width: 800px; max-width: 100%;">
            <p>This is a project solving a website game called <a href="https://en.gamesaien.com/game/fruit_box/">Fruit Box by GameSaien</a>, and I explained this project on my <a href="https://github.com/junsoup/Apple-Destroyer">Github</a>.</p>
            <p>Here is a short rundown of the game.</p>
            <ul>
                <li>There's a board of apples with numbers 1 through 9</li>
                <li>The player can make rectangular selections</li>
                <li>Selections that sum to 10 pop the apples and you get points for each apple.</li>
            </ul>
            <p>I spent days playing this game but the highest score I got was 109 out of 170. Can we do better?</p>
            <p>In this project I learned many concepts.</p>
            <ul>
                <li>Monte Carlo Tree Search algorithm</li>
                <li>Heuristics</li>
                <li>OpenCV</li>
                <li>pyautogui</li>
            </ul>
            <p>Unfortunately, I couldn't cause an apple extinction...</p>

        </div>
    </div>
    <footer>
        <p>by Junsu Lee</p>
    </footer>
</body>

</html>